# -*- coding: utf-8 -*-
"""Regresion TP1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tCrMPiYOD01lLz2EAtIWM9gLN1pAH4iG
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""##Carga de datos"""

##https://www.kaggle.com/datasets/kukuroo3/flight-price-predict-competition-format
#Importo datos
X_test=pd.read_csv('/content/drive/MyDrive/Uba/Maestria datos financieros/Metodos avanzados predictivo/Trabajos practicos/1/precios aereos/X_test.csv', sep=',')
X_test.head()

X_train=pd.read_csv('/content/drive/MyDrive/Uba/Maestria datos financieros/Metodos avanzados predictivo/Trabajos practicos/1/precios aereos/X_train.csv', sep=',')
X_train.head()

y_test=pd.read_csv('/content/drive/MyDrive/Uba/Maestria datos financieros/Metodos avanzados predictivo/Trabajos practicos/1/precios aereos/y_test.csv',sep=',')
y_test.head()

y_test=y_test['price']
y_test.head()

y_train=pd.read_csv('/content/drive/MyDrive/Uba/Maestria datos financieros/Metodos avanzados predictivo/Trabajos practicos/1/precios aereos/y_train.csv', sep=',')
y_train.head()

y_train=y_train['price']
y_train.head()

"""##Preparacion de datos"""

### veo dimension de los datos de entrenamiento
X_train.shape

### veo elementos faltantes
X_train.isnull().sum()

X_test.isnull().sum()

### tipos de datos
X_train.dtypes

X_train.columns

X_train.nunique()

### numerizo variables
X_train=pd.get_dummies(X_train,columns=['airline','source_city','departure_time', 'arrival_time', 'destination_city'])

###Analizo dimensionalidad por si se modifico la cantidad de columnas
X_train.shape

X_test=pd.get_dummies(X_test, columns=['airline','source_city','departure_time', 'arrival_time', 'destination_city'])

###Analizo dimensionalidad por si se modifico la cantidad de columnas
X_test.shape

X_train['stops'].unique()

## mapeo stops
X_test['stops']=X_test['stops'].map({'one':1, 'zero':0, 'two_or_more':2})

X_train['stops']=X_train['stops'].map({'one':1, 'zero':0, 'two_or_more':2})

X_test.head()

## Analizo outliers
outliers = plt.boxplot(X_train['duration'])['fliers'][0].get_data()[1]
print(outliers)

###reemplazo outliers con None
for i in [31.17,37.58,34.33,45.83, 32.,34.33,34.33]:
  X_train['duration']=X_train['duration'].replace({i:None},inplace=False)

X_train.isnull().sum()

X_train.head()

## Analizo outliers
outliers = plt.boxplot(X_test['duration'])['fliers'][0].get_data()[1]
print(outliers)

##Reemplazo por None los outliers
for i in [32.,35.08,34.33,36.17,35.08]:
  X_test['duration']=X_test['duration'].replace({i:None},inplace=False)

X_test.isnull().sum()

X_train.head()

plt.boxplot(X_train['days_left'])['fliers'][0].get_data()[1]

plt.boxplot(X_test['days_left'])['fliers'][0].get_data()[1]

### Elimino vuelo y id flight
X_train=X_train.drop(['flight','filghtId'],axis=1)

X_test=X_test.drop(['flight','filghtId'], axis=1)

### normalizo datos
X_train=(X_train-X_train.min())/(X_train.max()-X_train.min())
X_test=(X_test-X_test.min())/(X_test.max()-X_test.min())

### imputo valores faltantes con vecino mas cercano
from sklearn.impute import KNNImputer

X_train.columns

X_test.columns

###imputo en X_train
imp=KNNImputer(n_neighbors=3, weights='distance')
temp=imp.fit_transform(X_train.to_numpy())

print(temp)

X_train=pd.DataFrame(temp,columns=['stops', 'duration', 'days_left', 'airline_AirAsia',
       'airline_Air_India', 'airline_GO_FIRST', 'airline_Indigo',
       'airline_SpiceJet', 'airline_Vistara', 'source_city_Bangalore',
       'source_city_Chennai', 'source_city_Delhi', 'source_city_Hyderabad',
       'source_city_Kolkata', 'source_city_Mumbai', 'departure_time_Afternoon',
       'departure_time_Early_Morning', 'departure_time_Evening',
       'departure_time_Late_Night', 'departure_time_Morning',
       'departure_time_Night', 'arrival_time_Afternoon',
       'arrival_time_Early_Morning', 'arrival_time_Evening',
       'arrival_time_Late_Night', 'arrival_time_Morning', 'arrival_time_Night',
       'destination_city_Bangalore', 'destination_city_Chennai',
       'destination_city_Delhi', 'destination_city_Hyderabad',
       'destination_city_Kolkata', 'destination_city_Mumbai'])

###imputo faltantes en X_test
temp2=imp.fit_transform(X_test.to_numpy())

X_test=pd.DataFrame(temp2,columns=['stops', 'duration', 'days_left', 'airline_AirAsia',
       'airline_Air_India', 'airline_GO_FIRST', 'airline_Indigo',
       'airline_SpiceJet', 'airline_Vistara', 'source_city_Bangalore',
       'source_city_Chennai', 'source_city_Delhi', 'source_city_Hyderabad',
       'source_city_Kolkata', 'source_city_Mumbai', 'departure_time_Afternoon',
       'departure_time_Early_Morning', 'departure_time_Evening',
       'departure_time_Late_Night', 'departure_time_Morning',
       'departure_time_Night', 'arrival_time_Afternoon',
       'arrival_time_Early_Morning', 'arrival_time_Evening',
       'arrival_time_Late_Night', 'arrival_time_Morning', 'arrival_time_Night',
       'destination_city_Bangalore', 'destination_city_Chennai',
       'destination_city_Delhi', 'destination_city_Hyderabad',
       'destination_city_Kolkata', 'destination_city_Mumbai'])

###analizo correlaciones
train=X_train

train['price']=y_train

train_corr=train.corr()
plt.figure(figsize=(20,20) )
sns.heatmap(train_corr, annot=True, cmap='coolwarm', linewidths=0.6,fmt=".2f")
plt.title('Mapa de Calor de Correlación')
plt.show()

test=X_test
test['price']=y_test

test_corr=test.corr()
plt.figure(figsize=(20,20) )
sns.heatmap(train_corr, annot=True, cmap='coolwarm', linewidths=0.6,fmt=".2f")
plt.title('Mapa de Calor de Correlación')
plt.show()

"""##MODELADO

###GradientBoostingRegressor
"""

###instalo librerias
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score,cross_validate
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error

###genero modelo
modelo1=GradientBoostingRegressor()

###determino rango de parametros para gridsearch
parametros1={'n_estimators':[25,75,100,150,210,300],
             'learning_rate':[0.01,.05,.1,.25,.5,.75,1],
             'max_depth':[2,4,6,8,10]}

###busco optimizar mejores hiperparametros con cross validation
gridsearch1=GridSearchCV(modelo1,parametros1,cv=5,scoring='neg_mean_squared_error',n_jobs=-1)
###entreno modelo
gridsearch1.fit(X_train,y_train)
###obtengo mejores hiperparametros
# Imprimimos los mejores parámetros y la mejor puntuación
print("Mejores parámetros encontrados:", gridsearch1.best_params_)
print("Mejor puntuación de validación cruzada:", gridsearch1.best_score_)

### predigo en base a los mejores hiperparametros
y_pred1=gridsearch1.predict(X_test)

mse1=mean_squared_error(y_test,y_pred1)
print('Mean squared error:',mse1)

# Crear el gráfico de dispersión
plt.scatter(y_test, y_pred1, color='blue', label='Valores Predichos')

# Etiquetas y leyenda
plt.xlabel('Valores Reales')
plt.ylabel('Valores Predichos')
plt.title('Gráfico de Dispersión de Valores Reales vs. Valores Predichos')
plt.legend()

# Mostrar el gráfico
plt.show()

"""###Redes neuronales"""

from tensorflow import keras

###genero modelo de redes secuenciales
modelo3=keras.Sequential()
### capa de entrada
modelo3.add(keras.layers.Input(shape=X_train.shape[1]))
### capas ocultas
for n in [512,256,128,64,8]:
  modelo3.add(keras.layers.Dense(n, activation='relu'))
### capa de salida
modelo3.add(keras.layers.Dense(1, activation='linear'))

metrics=[keras.metrics.MeanSquaredError(name="mean_squared_error")]
modelo3.compile(optimizer="adam", loss="mean_squared_error",metrics=metrics)

history=modelo3.fit(X_train, y_train,batch_size=512 ,epochs=100,verbose=2)
history=pd.DataFrame(history.history)

## predigo con datos de validacion
y_pred3=modelo3.predict(X_test)

print(y_pred3)

###obtengo el error cuadratico medio
mse3=mean_squared_error(y_test,y_pred3)
print('Mean squared error:', mse3)

# Crear el gráfico de dispersión
plt.scatter(y_test, y_pred3, color='blue', label='Valores Predichos')

# Etiquetas y leyenda
plt.xlabel('Valores Reales')
plt.ylabel('Valores Predichos')
plt.title('Gráfico de Dispersión de Valores Reales vs. Valores Predichos')
plt.legend()

# Mostrar el gráfico
plt.show()

"""Conclusion: En este caso al usar la metrica de Error medio cuadrado nos da que la red neuronal predice mejor el precio que GradientBoostingRegressor"""